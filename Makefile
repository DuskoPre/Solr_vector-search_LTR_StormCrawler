# Makefile with real all-MiniLM-L6-v2 embeddings and Wikipedia scraping
.PHONY: up down seed query setup-ltr setup-collection logs clean status real-scrape

# Default target - complete setup with real embeddings
all: setup

# Setup the complete stack with real Wikipedia content
setup: up setup-collection setup-ltr real-scrape
	@echo ""
	@echo "ðŸŽ‰ Complete hybrid search stack is ready!"
	@echo "ðŸ“Š Features:"
	@echo "   âœ… Solr with vector search (all-MiniLM-L6-v2, 384 dims)"
	@echo "   âœ… LTR re-ranking with 6 features"
	@echo "   âœ… Real Wikipedia content scraped and vectorized"
	@echo "   âœ… StormCrawler for continuous crawling"
	@echo ""
	@echo "ðŸ”— Access Points:"
	@echo "   ðŸ“Š Solr UI: http://localhost:8983"
	@echo "   ðŸŒªï¸  Storm UI: http://localhost:8081"
	@echo "   ðŸ§  Embeddings: http://localhost:8080/health"
	@echo ""
	@echo "ðŸš€ Next Steps:"
	@echo "   ðŸ“‹ Try: make query"
	@echo "   ðŸ“ˆ Monitor: make status"
	@echo "   ðŸ” Add URLs: make add-urls"

# Start all services
up:
	@echo "ðŸš€ Starting Solr + Vector Search + LTR + StormCrawler stack..."
	docker-compose up -d
	@echo "â³ Waiting for services (all-MiniLM-L6-v2 model loading may take 1-2 minutes)..."
	./scripts/wait-for-services.sh

# Stop all services
down:
	@echo "ðŸ›‘ Stopping all services..."
	docker-compose down

# Setup Solr collection with 384-dimensional vector search (all-MiniLM-L6-v2)
setup-collection:
	@echo "ðŸ“‹ Creating hybrid search collection (384-dim vectors)..."
	./scripts/setup-collection.sh

# Setup LTR features and models
setup-ltr:
	@echo "ðŸŽ¯ Setting up Learning-to-Rank with 6 features..."
	./scripts/setup-ltr.sh

# Scrape real Wikipedia content and generate actual embeddings
real-scrape:
	@echo "ðŸŒ Scraping real Wikipedia content with all-MiniLM-L6-v2 embeddings..."
	./scripts/enhanced-seed-with-real-scraping.sh

# Run comprehensive query examples with real embeddings
query:
	@echo "ðŸ” Running real-world queries with all-MiniLM-L6-v2..."
	./scripts/real-world-query-examples.sh

# Add more URLs for crawling
add-urls:
	@echo "ðŸ“‹ Adding more URLs to crawl queue..."
	@echo "Enter URLs (one per line, empty line to finish):"
	@while read -r url; do \
		if [ -z "$url" ]; then break; fi; \
		redis-cli -h localhost -p 6379 LPUSH "crawl.queue" "$url"; \
		echo "  âœ… Added: $url"; \
	done
	@echo "ðŸ“Š Queue length: $(redis-cli -h localhost -p 6379 LLEN 'crawl.queue')"

# Monitor logs from all services
logs:
	docker-compose logs -f

# Check detailed status of all services and data
status:
	@echo "ðŸ“Š === HYBRID SEARCH STACK STATUS ==="
	@echo ""
	@echo "ðŸ³ Docker Services:"
	@docker-compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"
	@echo ""
	@echo "ðŸ”— Health Checks:"
	@printf "   Solr: "
	@curl -s http://localhost:8983/solr/admin/ping 2>/dev/null | grep -q '"status":"OK"' && echo "âœ… Ready" || echo "âŒ Not Ready"
	@printf "   Storm UI: "
	@curl -s http://localhost:8081 >/dev/null 2>&1 && echo "âœ… Ready" || echo "âŒ Not Ready"
	@printf "   Embeddings (all-MiniLM-L6-v2): "
	@curl -s http://localhost:8080/health 2>/dev/null | grep -q '"status":"healthy"' && echo "âœ… Ready" || echo "âŒ Not Ready"
	@printf "   Redis: "
	@redis-cli -h localhost -p 6379 ping >/dev/null 2>&1 && echo "âœ… Ready" || echo "âŒ Not Ready"
	@echo ""
	@echo "ðŸ“ˆ Data Statistics:"
	@printf "   Documents indexed: "
	@curl -s "http://localhost:8983/solr/hybrid_search/select?q=*:*&rows=0" 2>/dev/null | jq -r '.response.numFound // "Error"'
	@printf "   URLs in crawl queue: "
	@redis-cli -h localhost -p 6379 LLEN "crawl.queue" 2>/dev/null || echo "Error"
	@printf "   Index size: "
	@curl -s "http://localhost:8983/solr/hybrid_search/admin/luke?numTerms=0" 2>/dev/null | jq -r '.index.sizeInBytes // "Error"' | numfmt --to=iec 2>/dev/null || echo "Error"
	@echo ""
	@echo "ðŸŽ¯ LTR Model Status:"
	@curl -s "http://localhost:8983/solr/hybrid_search/schema/model-store" 2>/dev/null | jq -r '.models[]?.name // "No models found"'

# Test embedding service specifically
test-embeddings:
	@echo "ðŸ§  Testing all-MiniLM-L6-v2 embedding service..."
	@echo "Query: 'machine learning algorithms'"
	@curl -s "http://localhost:8080/encode" \
		-H "Content-Type: application/json" \
		-d '{"text": "machine learning algorithms"}' | \
		jq '{model: .model, dimension: .dimension, first_5_values: .embedding[0:5]}'

# Run performance benchmarks
benchmark:
	@echo "âš¡ Running performance benchmarks..."
	@echo "Testing query latency (10 queries)..."
	@for i in {1..10}; do \
		time curl -s "http://localhost:8983/solr/hybrid_search/select?q=machine+learning&defType=edismax&qf=title^2+content&rq={!ltr+model=hybrid_ranker+reRankDocs=20}&rows=5" >/dev/null; \
	done

# Clean everything including data
clean: down
	@echo "ðŸ§¹ Cleaning up all data and volumes..."
	docker-compose down -v
	docker volume prune -f
	docker system prune -f
	@echo "âœ… Cleanup complete!"
